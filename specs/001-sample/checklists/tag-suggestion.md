# Tag Suggestion Feature Requirements Quality Checklist

**Purpose**: Validate that tag suggestion feature requirements (FR-003, FR-014) are complete, clear, and implementation-ready for the OpenSearch + Model2Vec hybrid approach.
**Created**: 2025-11-14
**Feature**: specs/001-sample/spec.md
**Focus**: Tag auto-suggestion component (T042-T047)
**Depth**: Quick validation (10-15 items)
**Audience**: Author self-check before implementation

**Note**: This checklist is generated by the `/speckit.checklist` command based on feature context and requirements.

## Requirement Completeness

- [X] CHK001 Are the exact inputs required for tag suggestion generation (article content, metadata, length threshold) explicitly specified? [Completeness, Gap]
  **✓ COMPLETE**: FR-003 now specifies "combined article title and body content" with 100 character minimum length threshold. Session 2025-11-14 clarifications explicitly document: title + body concatenated as source text, <100 chars triggers "Content too short" message.

- [X] CHK002 Is the hybrid scoring algorithm (OpenSearch + Model2Vec) documented with explicit weighting percentages and combination logic? [Clarity, Spec §FR-003]
  **✓ COMPLETE**: FR-003 now explicitly documents "hybrid scoring (70% semantic + 30% frequency)" with ≥0.3 threshold on 0-1 scale. Session 2025-11-14 clarification captured the weighting formula from research.md into the functional requirement.

- [X] CHK003 Are the data flow and service dependencies between OpenSearch, Lambda, and the frontend API endpoint explicitly mapped? [Completeness, Gap]
  **✓ COMPLETE**: FR-003 now specifies service orchestration: "Next.js API route invokes AWS Lambda, which queries OpenSearch for keyword extraction, applies Model2Vec semantic ranking with hybrid scoring, and returns ranked results." Session 2025-11-14 clarification documented the full flow.

## Requirement Clarity

- [X] CHK004 Is the "relevance-ranked order" criteria quantified with measurable sorting rules? [Clarity, Spec §FR-003]
  **✓ COMPLETE**: FR-003 now specifies "relevance-ranked order (highest score first)" where relevance is the combined hybrid score (70% semantic + 30% frequency). Session 2025-11-14 clarification defines sorting by hybrid score descending.

- [X] CHK005 Are the timeout boundaries specified for each component (OpenSearch extraction timeout, Model2Vec inference timeout, total end-to-end timeout)? [Clarity, Spec §SC-005]
  **✓ COMPLETE**: SC-005 now includes "Component targets: OpenSearch keyword extraction ≤1s, Model2Vec semantic ranking ≤1.5s, network overhead ≤0.5s." Session 2025-11-14 clarification allocated the 3s total budget across components. OR-002 adds component-level metrics for monitoring.

- [X] CHK006 Is the behavior for "fewer than 5 quality candidates" quantified with specific quality thresholds? [Clarity, Edge Case]
  **✓ COMPLETE**: FR-003 now specifies "Only tags with a combined hybrid score of ≥0.3 on a 0-1 scale qualify as quality candidates." Edge Cases updated to document: return fewer than 5 if <5 meet threshold, return 0 with "No quality tag suggestions found" if none meet threshold. Session 2025-11-14 clarification defined quality threshold.

## Scenario Coverage

- [X] CHK007 Are requirements defined for empty content scenarios (blank article, whitespace-only, <N characters)? [Coverage, Edge Case]
  **✓ COMPLETE**: FR-003 now specifies "If the combined content length is less than 100 characters, the system MUST display the message 'Content too short for tag suggestions. Add more content or add tags manually.'" Session 2025-11-14 clarification set minimum threshold at 100 characters with explicit error message.

- [X] CHK008 Are multilingual content handling requirements specified (language detection, per-language tag extraction, mixed-language scoring)? [Coverage, Edge Case]
  **✓ COMPLETE**: FR-003 now specifies "The system handles multilingual content (Japanese, English, mixed-language) seamlessly without language detection" using "Japanese-focused multilingual Model2Vec model." Session 2025-11-14 clarification chose language-agnostic semantic embeddings approach—no detection needed, works with mixed content.

- [X] CHK009 Are partial failure scenarios defined (OpenSearch succeeds but Model2Vec fails, vice versa, both fail)? [Coverage, Exception Flow]
  **✓ COMPLETE**: T045 implementation defines all partial failure scenarios: (1) OpenSearch succeeds + Model2Vec fails → return frequency-only tags with "using frequency-only scoring" message; (2) OpenSearch fails (regardless of Model2Vec status) → total failure (cannot proceed without keywords); (3) Both fail → total failure with "Both components failed. You can retry by clicking 'Suggest Tags' again." Test coverage validates all scenarios in handler.test.ts lines 552-613.

## Non-Functional Requirements Quality

- [X] CHK010 Are the latency requirements broken down by component (OpenSearch extraction ≤Xms, Model2Vec inference ≤Yms, network overhead ≤Zms) to enable targeted optimization? [Measurability, Spec §SC-005]
  **✓ COMPLETE**: SC-005 now specifies "Component targets: OpenSearch keyword extraction ≤1s, Model2Vec semantic ranking ≤1.5s, network overhead ≤0.5s" and OR-002 adds component-level metrics (tag_suggestion.opensearch_latency_ms, tag_suggestion.model2vec_latency_ms, tag_suggestion.network_latency_ms). Session 2025-11-14 clarification decomposed 3s budget for targeted monitoring.

- [ ] CHK011 Is the Model2Vec model size constraint (8-30MB per research.md:67) documented as a requirement to prevent future model swaps that break Lambda deployment? [Completeness, Gap]
  **✗ INCOMPLETE**: research.md:67 mentions ~8-30MB model size optimized for Lambda deployment, but this critical constraint is not captured in FR-003 or Success Criteria. Future model swaps could exceed Lambda package size limits (250MB unzipped) if not documented as a requirement. Recommend adding to FR-003 or creating new NFR.

- [ ] CHK012 Are cold start latency requirements specified (acceptable delay on first invocation, warm instance retention strategy)? [Completeness, Gap]
  **✗ INCOMPLETE**: research.md:74 documents 500-800ms cold start expectation, but requirements don't specify if this is within acceptable UX (1.5s Model2Vec budget accommodates it) or if warm instance provisioning strategies are required. The 1.5s component budget implicitly accepts cold starts, but explicit documentation would clarify intent.

## Operational & Observability Requirements

- [X] CHK013 Are the required metrics (tag_suggestion.latency_ms, tag_suggestion.success_rate) defined with explicit measurement points (client-side? server-side? Lambda-internal?)? [Clarity, Spec §OR-002]
  **✓ COMPLETE**: OR-002 now specifies component-level metrics (tag_suggestion.opensearch_latency_ms, tag_suggestion.model2vec_latency_ms, tag_suggestion.network_latency_ms) in addition to end-to-end tag_suggestion.latency_ms and tag_suggestion.success_rate. The component breakdown clarifies Lambda-internal vs network measurement points. Session 2025-11-14 clarification added granular metrics for debugging.

- [X] CHK014 Are fallback behavior validation criteria specified (how to verify graceful degradation works in production)? [Measurability, Spec §FR-014]
  **✓ COMPLETE**: T045 implements testable fallback behavior with validation in handler.test.ts: (1) Frequency-only fallback test validates message contains "frequency-only" (line 575); (2) Component latency metrics test verifies metrics.opensearchLatencyMs and metrics.model2vecLatencyMs are tracked (lines 654-682); (3) 3-second timeout test validates duration ≤3500ms (line 549). Production validation criteria deferred to T047 (metrics implementation) - will track tag_suggestion.success_rate for alert thresholds.

- [X] CHK015 Is the retry/backoff strategy for tag suggestion failures documented (immediate retry? exponential backoff? manual retry only)? [Gap, Exception Flow]
  **✓ COMPLETE**: T045 implements manual retry only policy: (1) No automatic retries at Lambda level; (2) When both components fail, response includes message: "Both components failed. You can retry by clicking 'Suggest Tags' again." (handler.ts line 190); (3) User must manually click "Suggest Tags" button again to retry; (4) No exponential backoff - each retry is independent. Test validates retry message in handler.test.ts lines 684-702. Simple strategy chosen for v1 as recommended in checklist.

## Ambiguities & Conflicts

- [X] CHK016 Does the "Suggest Tags" manual trigger requirement conflict with auto-save workflow expectations? [Conflict, Spec §FR-003]
  **✓ RESOLVED**: FR-003 explicitly specifies manual trigger via "Suggest Tags" button (Session 2025-11-14 clarification). Auto-save (T050) handles draft persistence only; tag suggestions remain separate user action. No conflict—tags are part of article metadata that persists with auto-save after user generates/edits them, but generation itself is manual. Clear separation of concerns.

---

## Checklist Summary

**Total Items**: 16
**Completed**: 14 (CHK001-010, CHK013-016)
**Remaining**: 2 (CHK011, CHK012)

**Status**: ✅ **T045 COMPLETE** - Timeout and fallback implementation finished

**Resolved (Session 2025-11-14)**:
- ✅ Input specification (title + body, 100 char minimum)
- ✅ Hybrid scoring algorithm (70/30 weighting, ≥0.3 threshold)
- ✅ Service orchestration flow (Next.js → Lambda → OpenSearch)
- ✅ Component timeout allocation (1s/1.5s/0.5s)
- ✅ Multilingual handling (Japanese-focused Model2Vec, language-agnostic)
- ✅ Quality candidate definition and ranking criteria
- ✅ Component-level observability metrics

**Resolved (T045 Implementation - 2025-11-18)**:
- ✅ CHK009: Partial failure scenarios implemented (frequency-only fallback when Model2Vec fails)
- ✅ CHK014: Fallback behavior validation implemented with comprehensive test coverage
- ✅ CHK015: Manual retry only policy implemented (no automatic retries, user-triggered)

**Remaining (Non-Blocking for Core Feature)**:
- CHK011: Model size constraint documentation (operational concern, monitoring in production)
- CHK012: Cold start requirements (1.5s budget already accommodates, implicit acceptance)

**Recommendation**: ✅ **PROCEED WITH T046-T047 (API ROUTE)**. All core Lambda handler requirements complete with full test coverage (25 tests passing). Remaining items are operational documentation refinements.
